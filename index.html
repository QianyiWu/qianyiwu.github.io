<!DOCTYPE html>
<!--[if lt IE 8 ]><html class="no-js ie ie7" lang="en"> <![endif]-->
<!--[if IE 8 ]><html class="no-js ie ie8" lang="en"> <![endif]-->
<!--[if (gte IE 8)|!(IE)]><!--><html class="no-js" lang="en"> <!--<![endif]-->
<head>

   <!--- Basic Page Needs
   ================================================== -->
  <meta charset="utf-8">
	<title>Qianyi Wu</title>
	<meta name="description" content="Research and Personal Projects">
	<meta name="author" content="qianyi">

   <!-- Mobile Specific Metas
   ================================================== -->
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<!-- CSS
    ================================================== -->
   <link rel="stylesheet" href="css/default.css">
	 <link rel="stylesheet" href="css/layout.css">
   <link rel="stylesheet" href="css/academicons/css/academicons.css"/>
   <link rel="stylesheet" href="css/media-queries.css">
   <link rel="stylesheet" href="css/magnific-popup.css">

   <!-- Script
   ================================================== -->
	<script src="js/modernizr.js"></script>

   <!-- Icon
	================================================== -->
	<link rel="shortcut icon" href="media/my_image.jpg" >

</head>

<body>


   <!-- About Section
   ================================================== -->
   <section id="about">
      <nav id="nav-wrap">

        <a class="mobile-btn" href="#nav-wrap" title="Show navigation">Show navigation</a>
	      <a class="mobile-btn" href="#" title="Hide navigation">Hide navigation</a>

         <ul id="nav" class="nav">
            <li class="current"><a class="smoothscroll" href="#about">About</a></li>
            <li><a class="smoothscroll" href="#publication">Publications</a></li>
            <!--li><a class="smoothscroll" href="#research">Research</a></li-->
            <!-- <li><a class="smoothscroll" href="#Link">Link</a></li> -->

         </ul> <!-- end #nav -->

      </nav> <!-- end #nav-wrap -->

      <div class="row">

         <div class="three columns">

            <img class="profile-pic"  src="media/my_image.jpg" alt="" />

         </div>

         <div class="nine columns main-col">

            <h1><font color="white">Qianyi Wu</font></h1>

            <!-- <h5> <font color="white"> Doktorand, Perceiving Systems </font> </h5> -->
            <h5> <font color="white"> University of Science and Technology of China </font> </h5>
            <font color="white"> wqy9619_at_mail.ustc.edu.cn </font>
            <footer>
              <div class="row">

               <div class="twelve columns">
                  <ul class="social-links">
                     <!-- <li><a href="https://scholar.google.de/citations?user=K-Xbnp8AAAAJ" target="_blank"><i class="fa fa-google-scholar"></i></a></li> -->
                     <li><a href="https://github.com/QianyiWu" target="_blank"><i class="fa fa-github"></i></a></li>
                     <li><a href="media/CV.pdf" target="_blank"><i class="fa fa-file"></i></a></li>
                     <!-- <li><a href="https://medium.com/@anuragranj" target="_blank"><i class="fa fa-medium"></i></a></li> -->
                     <!-- <li><a href="http://ca.linkedin.com/pub/anurag-ranjan/20/553/295" target="_blank"><i class="fa fa-linkedin"></i></a></li> -->
                  </ul>
               </div>
              </div>
            </footer>
         </div>

     </div> <!-- end .main-col -->

      </div>

      <p class="scrolldown">
         <a class="smoothscroll" href="#about"><i class="icon-down-circle"></i></a>
      </p>


</section> <!-- About Section End-->


 


<section id="teser">

 <div class="row add-bottom">
   <p class="lead">
     Qianyi Wu is currently an Master student in School of Mathematical Sciences at University of Science and Technology of China (USTC), under the supervision of <a href="http://staff.ustc.edu.cn/~juyong/">Prof. Juyong Zhang</a>. He obtained his Bachelor’s degree from USTC in 2016.
     
   </p>
  <h5>Timeline. </h5>
  <dl class="lining">
 <!--    <dt> Fall 2018</dt> <dd>  Research Intern, NVIDIA Research </dd>
    <dt> Summer 2017</dt> <dd>  Research Intern, Applied Machine Learning, Facebook Research </dd>
    <dt> Since 2016</dt> <dd> PhD Student, Max Planck Institute for Intelligent Systems </dd>
    <dt> Fall 2015</dt> <dd> Software Developer, Mashup Machine Inc., Vancouver </dd>
    <dt> 2013 - 2015</dt> <dd>  Masters Student, Computer Science, University of British Columbia</dd> -->
    <dt> Since 2016</dt> <dd> Matser student, Univeristy of Science and Techonology of China, P.R.China</dd>
    <dt> 2017.8 - 2018.8</dt> <dd> Research Intern at Nanyang Techonology University, Singapore. Under supervision of <a href="http://www.ntu.edu.sg/home/asjfcai/">Prof.Jianfei Cai</a> and <a href="http://www.ntu.edu.sg/home/asjmzheng/">Prof.Jianmin Zheng</a></dd> 
    <dt> 2012 - 2016</dt> <dd> Undergrad, Univeristy of Science and Technology of China, P.R.China</dd>
  </ul>
 </div>
</section>
   <!--Publication Section
   ================================================== -->
   <section id="publication">

    <div class="row add-bottom">

         <div class="twelve columns">

            <h1 align="center">Publications</h1>
<!--             <hr>
            <div class="row add-bottom">
              <h2 align=center> Adversarial Collaboration</h2>
              <h3 align=center> Joint Unsupervised Learning of Depth, Camera <br> Motion, Optical Flow and Motion Segmentation </h3>
              <p align="center", class="lead add-bottom">
                Anurag Ranjan, Varun Jampani, Kihwan Kim, Deqing Sun, Jonas Wulff, Michael J. Black
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/ac_tease.jpg" >
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        We address the unsupervised learning of several interconnected problems in low-level vision: single view depth prediction, camera motion estimation, optical flow and segmentation
                        of a video into the static scene and moving regions. Our model is trained without any supervision and achieves state of the art results amongst unsupervised methods.
                      </p>
                      <p class="paper-links" align="center"> <a href="https://ps.is.tuebingen.mpg.de/publications/adversarial-collaboration" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                        <a href="https://github.com/anuragranj/ac" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://arxiv.org/abs/1805.09806" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr> -->

            <div class="row add-bottom">
              <h2 align=center> Alive Caricature from 2D to 3D </h2>
              <p align="center", class="lead add-bottom">
                Qianyi Wu, Juyong Zhang, Yu-Kun Lai, Jianmin Zheng, Jianfei Cai (CVPR 2018)(spotlight)
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/Caricature.jpg" >
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                      A non-linear representation used for generating 3D caricature by 2D image and its annotated facial landmarks. 
                      </p>
                      <p class="paper-links" align="center"> 
                        <a href="https://github.com/QianyiWu/Caricature-Data" target="_blank" title="Data"><i class="fa fa-github"></i></a>
                        <a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Wu_Alive_Caricature_From_CVPR_2018_paper.pdf" target="_blank" title="Paper"><i class="fa fa-file"></i></a>
                        <a href="https://www.technologyreview.com/s/610714/the-best-of-the-physics-arxiv-week-ending-march-31-2018/" target="_blank" title="News"><i class="fa fa-external-link"></i></a>
                      </p>
                    </div>
                </div>

              </div>
            <hr>

            <!-- <div class="row add-bottom">
              <h2 align=center> Unsupervised Learning of Multi-Frame Optical Flow with Occlusions </h2>
              <p align="center", class="lead add-bottom">
                Joel Janai, Fatma Güney, Anurag Ranjan, Michael J. Black and Andreas Geiger (ECCV 2018)
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="https://ps.is.tue.mpg.de/uploads/publication/image/20263/thumb_lg_joeleccv18.png" >
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        We propose a framework for unsupervised learning of optical flow and occlusions over multiple frames. Our multi-frame, occlusion-sensitive formulation outperforms existing unsupervised two-frame methods and even produces results on par with some fully supervised methods.
                      </p>
                      <p class="paper-links" align="center"> <a href="https://ps.is.tue.mpg.de/publications/janai2018eccv" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                        <a href="http://www.cvlibs.net/projects.php"" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="http://www.cvlibs.net/publications/Janai2018ECCV.pdf" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

            <div class="row add-bottom">
              <h2 align=center> Learning Human Optical Flow </h2>
              <p align="center", class="lead add-bottom">
                Anurag Ranjan, Javier Romero, Michael J. Black (BMVC 2018)
              </p>

                  <div class="row"> <div class="five columns">
                    <iframe width="420" height="200" src="https://www.youtube.com/embed/IFZbsDt9jMw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        Learning optical flow for humans is difficult. So, we created a synthetic dataset with realistic humans and trained a neural network on it.
                      </p>
                      <p class="paper-links" align="center"> <a href="http://humanflow.is.tue.mpg.de" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                        <a href="https://github.com/anuragranj/humanflow" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://arxiv.org/abs/1806.05666" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

            <div class="row add-bottom">
              <h2 align=center> SPyNet: Spatial Pyramid Network for Optical Flow </h2>
              <p align="center", class="lead add-bottom">
                Anurag Ranjan, Michael J. Black (CVPR 2017)
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/sintel_pyramid.jpg" >
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        SPyNet is the smallest deep network in the world that computes optical flow. It is smaller than Flownet by 97% and outperforms it significanly. Both code and trained models are available.
                      </p>
                      <p class="paper-links" align="center"> <a href="http://spynet.is.tue.mpg.de" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                        <a href="https://github.com/anuragranj/spynet" target="_blank" title="Code"><i class="fa fa-github"></i></a>
                        <a href="https://arxiv.org/abs/1611.00850" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

            <div class="row add-bottom">
              <h2 align=center> Interactive Gaze Driven Animation of the Eye Region </h2>
              <p align="center", class="lead add-bottom">
                Debanga R Neog, João L Cardoso, Anurag Ranjan, Dinesh K Pai (Web3D 2016)
              </p>

                  <div class="row"> <div class="five columns">
                    <iframe width="420" height="200" src="https://www.youtube.com/embed/FSae6RVllwQ" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        A system for real-time animation of eyes that can be interactively controlled in a WebGL. This is the first system for real-time animation of soft tissue movement around the eyes based on gaze input.                      </p>
                      <p class="paper-links" align="center"> <a href="http://www.cs.ubc.ca/research/eyemoveweb3d16/" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                      <a href="http://www.cs.ubc.ca/research/eyemoveweb3d16/Interactive%20Gaze%20Driven%20Animation%20of%20the%20Eye%20Region.pdf" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

            <div class="row add-bottom">
              <h2 align=center> Learning Periorbital Soft Tissue Motion </h2>
              <p align="center", class="lead add-bottom">
                Anurag Ranjan (Master's Thesis, UBC 2015)
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/periorbit.jpg" >
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        We model the soft tissues around the eyes that are associated with subtle and fast motions and convey emotions during facial expressions. Our data driven model that can efficiently learn and reproduce the complex motion of these periorbital soft tissues.
                        <p class="paper-links" align="center"> <a href="https://open.library.ubc.ca/cIRcle/collections/ubctheses/24/items/1.0166703" target="_blank" title="Project Page"><i class="fa fa-external-link"></i></a>
                        <a href="media/Learning_Periorbital_Soft_Tissue_Motion.pdf" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr>

            <div class="row add-bottom">
              <h2 align=center> Implementation of 3D object recognition and tracking </h2>
              <p align="center", class="lead add-bottom">
                Pankaj Bongale, Anurag Ranjan, Sahil Anand (RACSS 2012)
              </p>

                  <div class="row"> <div class="five columns">
                    <img src="images/obj_recog_pcl.jpg" >
                  </div>
                    <div class="seven columns">
                      <p class="add-bottom">
                        This object recognition and tracking system utilizes the depth information from a low-cost depth sensor. This approach makes use of the depth information and 3d properties of objects inorder to accurately identify them independent of lighting conditions.
                        <p class="paper-links" align="center">
                        <a href="media/object_recognition_point_clouds.pdf" target="_blank" title="Paper"><i class="fa fa-file"></i></a></p>
                    </div>
                </div>

              </div>
            <hr> -->

         </div>

      </div> <!-- Row End-->

   </section> <!-- Research Section End-->


      <!-- <-- Bio Section -->

    <section id="Link">
     <div class="row add-bottom">
        <div class="twelve columns" align="center">
          <h1></h1>
          <p> Life's a struggle.
        </div>
     </div>


   </section>

  <small> Template from <a href="http://www.Styleshout.com">http://www.Styleshout.com</a> </small>
   <!-- Java Script
   ================================================== -->
   <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
   <script>window.jQuery || document.write('<script src="js/jquery-1.10.2.min.js"><\/script>')</script>
   <script type="text/javascript" src="js/jquery-migrate-1.2.1.min.js"></script>

   <script src="js/jquery.flexslider.js"></script>
   <script src="js/waypoints.js"></script>
   <script src="js/jquery.fittext.js"></script>
   <script src="js/magnific-popup.js"></script>
   <script src="js/init.js"></script>
   <script>
  	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-105425042-1', 'auto');
  	ga('send', 'pageview');
  </script>

</body>

</html>
